{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [SSD-Mobilenet]\n",
    "* [SSD-Resnet50]\n",
    "\n",
    "\n",
    "[Docker Containers of the network](https://github.com/ctuning/ck-object-detection/tree/master/docker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Overview](#overview)\n",
    "1. [Platform](#platform)\n",
    "1. [Experimental data](#data) [for developers]\n",
    "1. [Data wrangling code](#code) [for developers]\n",
    "1. [Experiments on Hikey](#experiments_hikey)\n",
    "   1. [TensorFlow](#experiments_tensorflow_hikey)\n",
    "1. [Experiments on Firefly](#experiments_firefly)\n",
    "   1. [TensorFlow](#experiments_tensorflow_firefly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"overview\"></a>\n",
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook studies performance (execution time) vs accuracy (mAP and Recall) of different Object Detection networks, on different size objects (large, medium and small).\n",
    "Moreover the experiments are performed on different architectures, in particular CPU and GPU, to evaluate the benefit of GPU acceleration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"platform\"></a>\n",
    "## Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"CPU info\"></a>\n",
    "### CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Model:\n",
    "    - Intel Xeon\n",
    "  - Version:\n",
    "    - E5-2650 v3;  \n",
    "  - Frequency:\n",
    "    - 2.30GHz;\n",
    "  - Number of Cores (physical):\n",
    "    - 10\n",
    "  - HyperThreading\n",
    "    - Yes\n",
    "\n",
    "\n",
    "  - RAM:\n",
    "    - 32 GB;\n",
    "\n",
    "  - BSP:\n",
    "    - Ubuntu 16.04 LTS Linux\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"GPU info\"></a>\n",
    "### GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Model:\n",
    "    - Nvidia GeForce GTX 1080\n",
    "  - Frequency:\n",
    "    - 1.6GHz;\n",
    "  - CUDA Version:\n",
    "    - 10.2\n",
    "  - Driver Version:\n",
    "    - 430.14\n",
    "  - MEMORY:\n",
    "    - 8 GB;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data\"></a>\n",
    "## Get the experimental data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"code\"></a>\n",
    "## Data wrangling code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB:** Please ignore this section if you are not interested in re-running or modifying this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Includes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scientific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If some of the scientific packages are missing, please install them using:\n",
    "```\n",
    "# pip install jupyter pandas numpy matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython as ip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('IPython version: %s' % ip.__version__)\n",
    "print ('Pandas version: %s' % pd.__version__)\n",
    "print ('NumPy version: %s' % np.__version__)\n",
    "print ('Matplotlib version: %s' % mp.__version__)\n",
    "print ('Seaborn version: %s' % sb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "def display_in_full(df):\n",
    "    pd.options.display.max_columns = len(df.columns)\n",
    "    pd.options.display.max_rows = len(df.index)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_colormap = cm.autumn\n",
    "default_fontsize = 16\n",
    "default_barwidth = 0.8\n",
    "default_figwidth = 24\n",
    "default_figheight = 3\n",
    "default_figdpi = 200\n",
    "default_figsize = [default_figwidth, default_figheight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mp.__version__[0]=='2': mp.style.use('classic')\n",
    "mp.rcParams['figure.max_open_warning'] = 200\n",
    "mp.rcParams['figure.dpi'] = default_figdpi\n",
    "mp.rcParams['font.size'] = default_fontsize\n",
    "mp.rcParams['legend.fontsize'] = 'medium'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collective Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If CK is not installed, please install it using:\n",
    "```\n",
    "# pip install ck\n",
    "```\n",
    "\n",
    "If data are not present, download and add the repository to ck using:\n",
    "```\n",
    "!wget https://www.dropbox.com/s/532l5yb1qvxp8q6/my_experiments_0.zip?dl=0\n",
    "\n",
    "!mv my_experiments_0.zip\\?dl\\=0 my_experiments_0.zip\n",
    "!ck add repo:my-repo-with-experiments --zip=my_experiments_0.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ck.kernel as ck\n",
    "print ('CK version: %s' % ck.__version__)\n",
    "\n",
    "!wget https://www.dropbox.com/s/532l5yb1qvxp8q6/my_experiments_0.zip?dl=0\n",
    "\n",
    "!mv my_experiments_0.zip\\?dl\\=0 my_experiments_0.zip\n",
    "!ck add repo:my_repo_with_experiments --zip=my_experiments_0.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ck.kernel as ck\n",
    "print ('CK version: %s' % ck.__version__)\n",
    "\n",
    "\n",
    "    \n",
    "repo_uoa = 'my_repo_with_experiments'\n",
    "!ck list $repo_uoa:experiment:* | sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experimental_results(repo_uoa, tags='', accuracy=True,\n",
    "                             module_uoa='experiment', _library=None, _platform=None):\n",
    "    r = ck.access({'action':'search', 'repo_uoa':repo_uoa, 'module_uoa':module_uoa, 'tags':tags})\n",
    "    from pprint import pprint\n",
    "    pprint (r)\n",
    "    if r['return']>0:\n",
    "        print('Error: %s' % r['error'])\n",
    "        exit(1)\n",
    "    experiments = r['lst']\n",
    "\n",
    "    dfs = []\n",
    "    for experiment in experiments:\n",
    "        data_uoa = experiment['data_uoa']\n",
    "        r = ck.access({'action':'list_points', 'repo_uoa':repo_uoa, 'module_uoa':module_uoa, 'data_uoa':data_uoa})\n",
    "        pprint(r)\n",
    "        if r['return']>0:\n",
    "            print('Error: %s' % r['error'])\n",
    "            exit(1)\n",
    "        # Mapping of expected library tags to reader-friendly names.\n",
    "        tag_to_name = {\n",
    "            # ArmCL tags on HiKey.\n",
    "            '17.12-48bc34ea'    : 'armcl-17.12',\n",
    "            '18.01-f45d5a9b'    : 'armcl-18.01',\n",
    "            '18.03-e40997bb'    : 'armcl-18.03',\n",
    "            'request-d8f69c13'  : 'armcl-dv/dt', # armcl-18.03+\n",
    "            '18.05-b3a371bc'    : 'armcl-18.05',\n",
    "            # ArmCL tags on Firefly.\n",
    "            '17.12-48bc34e'     : 'armcl-17.12',\n",
    "            '18.01-f45d5a9'     : 'armcl-18.01',\n",
    "            '18.03-e40997b'     : 'armcl-18.03',\n",
    "            '18.05-b3a371b'     : 'armcl-18.05',\n",
    "            # TensorFlow tags.\n",
    "            'tensorflow-1.7'    : 'tensorflow-1.7',\n",
    "            'tensorflow-1.8'    : 'tensorflow-1.8',\n",
    "        }\n",
    "            \n",
    "        # Library.\n",
    "        library_tags = [ tag for tag in r['dict']['tags'] if tag in tag_to_name.keys() ]\n",
    "        #if len(library_tags)==1:\n",
    "        #    library = tag_to_name[library_tags[0]]\n",
    "        #else:\n",
    "        #    print('[Warning] Bad library tags. Skipping experiment with tags:')\n",
    "        #    print(r['dict']['tags'])\n",
    "        #    continue\n",
    "        #if _library and _library!=library: continue\n",
    "        # For each point.   \n",
    "        \n",
    "        pipeline_file_path = os.path.join(r['path'], 'pipeline.json')\n",
    "        with open(pipeline_file_path) as pipeline_file:\n",
    "            pipeline_data_raw = json.load(pipeline_file)\n",
    "        weights_env = pipeline_data_raw['dependencies']['weights']['dict']['env']\n",
    "        pprint(weights_env)\n",
    "        \n",
    "        tags = r['dict']['tags']\n",
    "        print (tags)\n",
    "        for point in r['points']:\n",
    "            point_file_path = os.path.join(r['path'], 'ckp-%s.0001.json' % point)\n",
    "            with open(point_file_path) as point_file:\n",
    "                point_data_raw = json.load(point_file)\n",
    "            characteristics_list = point_data_raw['characteristics_list']\n",
    "\n",
    "            pprint(characteristics_list)\n",
    "            print (\"****************************\")\n",
    "            print (point_data_raw.keys())\n",
    "            print (\"****************************\")\n",
    "            \n",
    "            pprint (point_data_raw['choices']['env'])\n",
    "            num_repetitions = len(characteristics_list)\n",
    "            platform = point_data_raw['features']['platform']['platform']['model']\n",
    "            #if _platform and _platform!=platform: continue\n",
    "            batch_size = np.int64(point_data_raw['choices']['env'].get('CK_BATCH_SIZE',-1))\n",
    "            batch_count = np.int64(point_data_raw['choices']['env'].get('CK_BATCH_COUNT',-1))\n",
    "            characteristics = characteristics_list[0]\n",
    "            #convolution_method = convolution_method_to_name[np.int64(point_data_raw['choices']['env'].get('CK_CONVOLUTION_METHOD_HINT',1))]\n",
    "            #if library.startswith('tensorflow-'):\n",
    "            #    multiplier = np.float64(point_data_raw['choices']['env'].get('CK_ENV_TENSORFLOW_MODEL_MOBILENET_MULTIPLIER',-1))\n",
    "            #    resolution = np.int64(point_data_raw['choices']['env'].get('CK_ENV_TENSORFLOW_MODEL_MOBILENET_RESOLUTION',-1))\n",
    "            #else:\n",
    "            #    multiplier = np.float64(point_data_raw['choices']['env'].get('CK_ENV_MOBILENET_WIDTH_MULTIPLIER',-1))\n",
    "            #    resolution = np.int64(point_data_raw['choices']['env'].get('CK_ENV_MOBILENET_RESOLUTION',-1))\n",
    "            #model = 'v1-%.2f-%d' % (multiplier, resolution)\n",
    "            if accuracy:\n",
    "                data = [\n",
    "                    {\n",
    "                        # features\n",
    "                        #'platform': platform,\n",
    "                        # choices\n",
    "                        #'weights_env': weights_env['CK_ENV_TENSORFLOW_MODEL_FROZEN_GRAPH'],\n",
    "                        'model': tags[0],\n",
    "                        'tf_version':tags[1],\n",
    "                        'batch_size': batch_size,\n",
    "                        'batch_count': batch_count,\n",
    "                        # runtime characteristics\n",
    "                        'mAP': characteristics['run'].get('mAP', 0)*100,\n",
    "                        'Recall': characteristics['run'].get('recall', 0)*100,\n",
    "                        'mAP_large': characteristics['run']['metrics'].get('DetectionBoxes_Recall/AR@100 (large)', 0)*100,\n",
    "                        'mAP_medium': characteristics['run']['metrics'].get('DetectionBoxes_Recall/AR@100 (medium)', 0)*100,\n",
    "                        'mAP_small': characteristics['run']['metrics'].get('DetectionBoxes_Recall/AR@100 (small)', 0)*100,\n",
    "#                         # recompute accuracy from frame_predictions (was incorrectly recorded in early experiments)\n",
    "#                         'accuracy_top1_': len([\n",
    "#                             prediction for prediction in characteristics['run'].get('frame_predictions', [])\n",
    "#                             if prediction['accuracy_top1']=='yes'\n",
    "#                         ]) / np.float64(batch_count),\n",
    "#                         'accuracy_top5_': len([\n",
    "#                             prediction for prediction in characteristics['run'].get('frame_predictions', [])\n",
    "#                             if prediction['accuracy_top5']=='yes'\n",
    "#                         ]) / np.float64(batch_count)\n",
    "                    }\n",
    "#                    for (repetition_id, characteristics) in zip(range(num_repetitions), characteristics_list)\n",
    "                ]\n",
    "            else: # performance\n",
    "                data = [\n",
    "                    {\n",
    "                        # features\n",
    "                        #'platform': platform,\n",
    "                        # choices\n",
    "                        #'weights_env': weights_env['CK_ENV_TENSORFLOW_MODEL_FROZEN_GRAPH'], \n",
    "                        'model': tags[0],\n",
    "                        'tf_version':tags[1],\n",
    "                        'batch_size': batch_size,\n",
    "                        'batch_count': batch_count,\n",
    "                        # statistical repetition\n",
    "                        'repetition_id': repetition_id,\n",
    "                        # runtime characteristics\n",
    "                        'avg_fps': characteristics['run'].get('avg_fps', 'n/a'),\n",
    "                        'avg_time_ms': characteristics['run']['avg_time_ms'],\n",
    "                        'graph_load_time_ms': characteristics['run']['graph_load_time_s']*1e+3,\n",
    "                        'images_load_time_avg_ms': characteristics['run']['images_load_time_avg_s']*1e+3,\n",
    "                    }\n",
    "                    for (repetition_id, characteristics) in zip(range(num_repetitions), characteristics_list)\n",
    "                ]\n",
    "            index = [\n",
    "                'model', 'tf_version', 'batch_size', 'batch_count'\n",
    "                #, 'mAP', 'Recall', 'mAP_large', 'mAP_medium', 'mAP_small'\n",
    "            ]\n",
    "            # Construct a DataFrame.\n",
    "            df = pd.DataFrame(data)\n",
    "            df = df.set_index(index)\n",
    "            # Append to the list of similarly constructed DataFrames.\n",
    "            dfs.append(df)\n",
    "    if dfs:\n",
    "        # Concatenate all thus constructed DataFrames (i.e. stack on top of each other).\n",
    "        result = pd.concat(dfs)\n",
    "        result.sort_index(ascending=True, inplace=True)\n",
    "    else:\n",
    "        # Construct a dummy DataFrame the success status of which can be safely checked.\n",
    "        result = pd.DataFrame(columns=['success?'])\n",
    "    return result\n",
    "!ck recache repo\n",
    "dfs = get_experimental_results(repo_uoa)\n",
    "\n",
    "dfs_per = get_experimental_results(repo_uoa,accuracy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot experimental data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot accuracy (bar plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(df_raw, groupby_level='batch_size', performance_metric=['mAP','mAP_large','mAP_medium','mAP_small'], title=None, figsize=None, rot=90):\n",
    "    from pprint import pprint\n",
    "    pprint(df_raw[performance_metric].values)\n",
    "    pprint(df_raw.index.values)\n",
    "    df_bar = pd.DataFrame(\n",
    "        data=df_raw[performance_metric].values, columns=performance_metric,\n",
    "        index=pd.MultiIndex.from_tuples(\n",
    "            tuples=[ (m,l,s,c) for (m,l,s,c) in df_raw.index.values ],\n",
    "            names=[ 'model', 'tf_version', 'batch_size', 'batch_count' ]\n",
    "        )\n",
    "    )\n",
    "    #groupby decide quanti plot fare.\n",
    "    #unstack come separare le colonne (?)\n",
    "    unstack_level = 'model'\n",
    "    colormap = cm.autumn\n",
    "    xlabel='(tf_version, batch_size)'\n",
    "    #df_bar.columns.names = ['time']\n",
    "    #if groupby_level=='convolution_method':\n",
    "    #    unstack_level = 'library'\n",
    "    #    xlabel='(Model [channel multiplier - input resolution], Convolution Method)'\n",
    "    #    colormap = cm.autumn\n",
    "    #elif groupby_level=='library':\n",
    "    #    unstack_level = 'convolution_method'\n",
    "    #    xlabel='(Library, Model [channel multiplier - input resolution])'\n",
    "    #    colormap = cm.summer\n",
    "    # Set default style.\n",
    "    ylabel='mAP %'\n",
    "    if not title: title = 'prova' \n",
    "    if not figsize: figsize = [default_figwidth, 8]\n",
    "    pprint (df_bar.index.names[:-1])\n",
    "    # Plot \n",
    "    mean = df_bar.groupby(level=df_bar.index.names[:-1]).mean().unstack(unstack_level)\n",
    "    std = df_bar.groupby(level=df_bar.index.names[:-1]).std().unstack(unstack_level)\n",
    "    axes = mean.groupby(level=groupby_level) \\\n",
    "        .plot(yerr=std, kind='bar', grid=True, width=0.8, rot=rot, figsize=figsize,\n",
    "              fontsize=default_fontsize, colormap=colormap)\n",
    "    for ax in axes:\n",
    "        # Title.\n",
    "        ax.set_title(title)\n",
    "        # X label.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        # Y axis.\n",
    "        ax.set_ylabel(ylabel)\n",
    "plot_accuracy(dfs, rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot performance (bar plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(df_raw, groupby_level='batch_size', performance_metric=['avg_fps','avg_time_ms','graph_load_time_ms','images_load_time_avg_ms'], title=None, figsize=None, rot=90):\n",
    "    from pprint import pprint\n",
    "    pprint(df_raw[performance_metric].values)\n",
    "    pprint(df_raw.index.values)\n",
    "    df_bar = pd.DataFrame(\n",
    "        data=df_raw[performance_metric].values, columns=performance_metric,\n",
    "        index=pd.MultiIndex.from_tuples(\n",
    "            tuples=[ (p,s,c,w) for (p,w,s,c) in df_raw.index.values ],\n",
    "            names=[ 'model', 'batch_size', 'batch_count', 'tf_version' ]\n",
    "        )\n",
    "    )\n",
    "    #groupby decide quanti plot fare.\n",
    "    #unstack come separare le colonne (?)\n",
    "    unstack_level = 'model'\n",
    "    colormap = cm.autumn\n",
    "    xlabel='(batch_count, tf_version)'\n",
    "    #df_bar.columns.names = ['time']\n",
    "    #if groupby_level=='convolution_method':\n",
    "    #    unstack_level = 'library'\n",
    "    #    xlabel='(Model [channel multiplier - input resolution], Convolution Method)'\n",
    "    #    colormap = cm.autumn\n",
    "    #elif groupby_level=='library':\n",
    "    #    unstack_level = 'convolution_method'\n",
    "    #    xlabel='(Library, Model [channel multiplier - input resolution])'\n",
    "    #    colormap = cm.summer\n",
    "    # Set default style.\n",
    "    ylabel=''\n",
    "    if not title: title = 'prova' \n",
    "    if not figsize: figsize = [default_figwidth, 8]\n",
    "    pprint (df_bar.index.names[:-1])\n",
    "    # Plot \n",
    "    mean = df_bar.groupby(level=df_bar.index.names[:-1]).mean().unstack(unstack_level)\n",
    "    std = df_bar.groupby(level=df_bar.index.names[:-1]).std().unstack(unstack_level)\n",
    "    axes = mean.groupby(level=groupby_level) \\\n",
    "        .plot(yerr=std, kind='bar', grid=True, width=0.8, rot=rot, figsize=figsize,\n",
    "              fontsize=default_fontsize, colormap=colormap)\n",
    "    for ax in axes:\n",
    "        # Title.\n",
    "        ax.set_title(title)\n",
    "        # X label.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        # Y axis.\n",
    "        ax.set_ylabel(ylabel)\n",
    "plot_performance(dfs_per, performance_metric=['avg_fps','avg_time_ms'])\n",
    "plot_performance(dfs_per, performance_metric=['graph_load_time_ms','images_load_time_avg_ms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
